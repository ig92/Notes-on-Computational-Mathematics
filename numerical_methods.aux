\relax 
\providecommand\zref@newlabel[2]{}
\providecommand\hyper@newdestlabel[2]{}
\bbl@cs{beforestart}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\@writefile{toc}{\@ifundefined{tof@begin}{\global \let \tof@begin\relax \global \let \tof@finish\@empty\global \let \tof@starttags\@gobble\global \let \tof@stoptags\@gobble\global \let \tof@tagthis\@gobble\global \let \tof@untagthis\@gobble}{}}
\@writefile{toc}{\tof@begin}
\@writefile{toc}{\contentsline {section}{\numberline {1}20th of September 2018 --- F. Poloni}{4}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}A warm up}{4}{subsection.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces How a change of basis reflects on the space.\relax }}{6}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:20sett1}{{1.1}{6}{How a change of basis reflects on the space.\relax }{figure.caption.2}{}}
\newlabel{fig:20sett1@cref}{{[figure][1][1]1.1}{[1][6][]6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Solving Linear Systems}{7}{subsection.1.2}\protected@file@percent }
\savepointas {row 1}{pgfid5}
\savepointas {col 1}{pgfid7}
\savepointas {row 2}{pgfid9}
\savepointas {row 3}{pgfid11}
\savepointas {row 4}{pgfid13}
\savepointas {row 5}{pgfid15}
\savepointas {row 6}{pgfid17}
\savepointas {row 7}{pgfid19}
\savepointas {row 8}{pgfid21}
\savepointas {row 9}{pgfid23}
\pgfsyspdfmark {pgfid4}{7026184}{40449916}
\pgfsyspdfmark {pgfid5}{14025443}{39499645}
\pgfsyspdfmark {pgfid6}{16395660}{39974780}
\pgfsyspdfmark {pgfid7}{19541395}{35170997}
\pgfsyspdfmark {pgfid8}{26232996}{40449916}
\pgfsyspdfmark {pgfid9}{29378731}{39499645}
\pgfsyspdfmark {pgfid10}{7151198}{31890918}
\pgfsyspdfmark {pgfid11}{10296933}{30940647}
\pgfsyspdfmark {pgfid12}{12612537}{32366054}
\pgfsyspdfmark {pgfid13}{15758272}{30465512}
\pgfsyspdfmark {pgfid14}{18454356}{31890918}
\pgfsyspdfmark {pgfid15}{19066027}{30940647}
\pgfsyspdfmark {pgfid16}{21199586}{31415783}
\pgfsyspdfmark {pgfid17}{24345321}{31415783}
\pgfsyspdfmark {pgfid18}{26859360}{31890918}
\pgfsyspdfmark {pgfid19}{28738063}{30940647}
\pgfsyspdfmark {pgfid20}{30999054}{31890918}
\pgfsyspdfmark {pgfid21}{34144789}{30940647}
\pgfsyspdfmark {pgfid22}{36873640}{31890918}
\pgfsyspdfmark {pgfid23}{40019375}{30940647}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces The adjacency matrix of a biparted graph has $0$s in its bottom left part (Matlab syntax \texttt  {A[p+1:n; 1:p]=0}), which means that the edges from a connected component and the other are in one direction only.\relax }}{9}{figure.caption.3}\protected@file@percent }
\newlabel{fig:20sett3}{{1.2}{9}{The adjacency matrix of a biparted graph has $0$s in its bottom left part (Matlab syntax \texttt {A[p+1:n; 1:p]=0}), which means that the edges from a connected component and the other are in one direction only.\relax }{figure.caption.3}{}}
\newlabel{fig:20sett3@cref}{{[figure][2][1]1.2}{[1][9][]9}}
\newlabel{exp1:20sett}{{1.2}{9}{}{example.1.2}{}}
\newlabel{exp1:20sett@cref}{{[example][2][1]1.2}{[1][9][]9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Orthogonality}{9}{subsection.1.3}\protected@file@percent }
\newlabel{def:20sett_norm}{{1.9}{9}{Norms}{definition.1.9}{}}
\newlabel{def:20sett_norm@cref}{{[definition][9][1]1.9}{[1][9][]9}}
\newlabel{fact:20sett}{{1.4}{10}{}{theorem.1.4}{}}
\newlabel{fact:20sett@cref}{{[proposition][4][1]1.4}{[1][10][]10}}
\@writefile{toc}{\contentsline {section}{\numberline {2}26th of September 2018 --- F. Poloni}{11}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Orthogonality (II)}{11}{subsection.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Matrix $U_1$ represents a rotation, while $U_2$ is a symmetry operation.\relax }}{11}{figure.caption.4}\protected@file@percent }
\newlabel{fig:26sett_ortho}{{2.1}{11}{Matrix $U_1$ represents a rotation, while $U_2$ is a symmetry operation.\relax }{figure.caption.4}{}}
\newlabel{fig:26sett_ortho@cref}{{[figure][1][2]2.1}{[1][11][]11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Eigenvalues / Eigenvector}{12}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Eigenvector: what could possibly go wrong?}{14}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{subfig:quad1}{{2.2(a)}{16}{Subfigure 2.2(a)}{subfigure.2.2.1}{}}
\newlabel{subfig:quad1@cref}{{[subfigure][1][2,2]2.2(a)}{[1][16][]16}}
\newlabel{sub@subfig:quad1}{{(a)}{16}{Subfigure 2.2(a)\relax }{subfigure.2.2.1}{}}
\newlabel{subfig:quad2}{{2.2(b)}{16}{Subfigure 2.2(b)}{subfigure.2.2.2}{}}
\newlabel{subfig:quad2@cref}{{[subfigure][2][2,2]2.2(b)}{[1][16][]16}}
\newlabel{sub@subfig:quad2}{{(b)}{16}{Subfigure 2.2(b)\relax }{subfigure.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces The plot of functions.\relax }}{16}{figure.caption.5}\protected@file@percent }
\newlabel{fig:26sett_quadratic}{{2.2}{16}{The plot of functions.\relax }{figure.caption.5}{}}
\newlabel{fig:26sett_quadratic@cref}{{[figure][2][2]2.2}{[1][16][]16}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {$f_1(x)$}}}{16}{figure.caption.5}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {$f_2(x)$}}}{16}{figure.caption.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}28th of September 2018 --- F. Poloni}{19}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Singular value decomposition (SVD)}{19}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Properties of SVD}{21}{subsubsection.3.1.1}\protected@file@percent }
\newlabel{prop:28sett_rank}{{3.1}{21}{}{theorem.3.1}{}}
\newlabel{prop:28sett_rank@cref}{{[property][1][3]3.1}{[1][21][]21}}
\pgfsyspdfmark {pgfid30}{21409297}{29873565}
\pgfsyspdfmark {pgfid31}{21409297}{29763246}
\pgfsyspdfmark {pgfid32}{27710710}{29052452}
\pgfsyspdfmark {pgfid33}{4736286}{24402596}
\newlabel{prop:28sett_norms}{{3.2}{21}{}{theorem.3.2}{}}
\newlabel{prop:28sett_norms@cref}{{[property][2][3]3.2}{[1][21][]21}}
\newlabel{fact:28sett_orthogonorm}{{3.3}{22}{}{theorem.3.3}{}}
\newlabel{fact:28sett_orthogonorm@cref}{{[proposition][3][3]3.3}{[1][22][]22}}
\@writefile{toc}{\contentsline {section}{\numberline {4}4th of October 2018 --- F. Poloni}{25}{section.4}\protected@file@percent }
\newlabel{subfloat:4ott_rk1}{{4.1(a)}{26}{Subfigure 4.1(a)}{subfigure.4.1.1}{}}
\newlabel{subfloat:4ott_rk1@cref}{{[subfigure][1][4,1]4.1(a)}{[1][25][]26}}
\newlabel{sub@subfloat:4ott_rk1}{{(a)}{26}{Subfigure 4.1(a)\relax }{subfigure.4.1.1}{}}
\newlabel{subfloat:4ott_rk2}{{4.1(b)}{26}{Subfigure 4.1(b)}{subfigure.4.1.2}{}}
\newlabel{subfloat:4ott_rk2@cref}{{[subfigure][2][4,1]4.1(b)}{[1][25][]26}}
\newlabel{sub@subfloat:4ott_rk2}{{(b)}{26}{Subfigure 4.1(b)\relax }{subfigure.4.1.2}{}}
\newlabel{subfloat:4ott_rk5}{{4.1(c)}{26}{Subfigure 4.1(c)}{subfigure.4.1.3}{}}
\newlabel{subfloat:4ott_rk5@cref}{{[subfigure][3][4,1]4.1(c)}{[1][25][]26}}
\newlabel{sub@subfloat:4ott_rk5}{{(c)}{26}{Subfigure 4.1(c)\relax }{subfigure.4.1.3}{}}
\newlabel{subfloat:4ott_rkfull}{{4.1(d)}{26}{Subfigure 4.1(d)}{subfigure.4.1.4}{}}
\newlabel{subfloat:4ott_rkfull@cref}{{[subfigure][4][4,1]4.1(d)}{[1][25][]26}}
\newlabel{sub@subfloat:4ott_rkfull}{{(d)}{26}{Subfigure 4.1(d)\relax }{subfigure.4.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces How the approximation of a matrix changes with respect to the different ranks.\relax }}{26}{figure.caption.6}\protected@file@percent }
\newlabel{fig:4ott_rank}{{4.1}{26}{How the approximation of a matrix changes with respect to the different ranks.\relax }{figure.caption.6}{}}
\newlabel{fig:4ott_rank@cref}{{[figure][1][4]4.1}{[1][25][]26}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Rank 1}}}{26}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Rank 2}}}{26}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {Rank 5}}}{26}{figure.caption.6}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {Full rank}}}{26}{figure.caption.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}10th of October 2018 --- F. Poloni}{26}{section.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces In this case the image of the matrix $A$ (in red) does not contain $b$ and the best one can do is to obtain a projection of $b$ in the plane $Im(A)$ (drawn in blue).\relax }}{27}{figure.caption.7}\protected@file@percent }
\newlabel{fig:10ott_1}{{5.1}{27}{In this case the image of the matrix $A$ (in red) does not contain $b$ and the best one can do is to obtain a projection of $b$ in the plane $Im(A)$ (drawn in blue).\relax }{figure.caption.7}{}}
\newlabel{fig:10ott_1@cref}{{[figure][1][5]5.1}{[1][27][]27}}
\@writefile{toc}{\contentsline {section}{\numberline {6}18th of October 2018 --- F. Poloni}{29}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Least squares problem}{29}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1}Method of normal equations}{30}{subsubsection.6.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Geometric idea.\relax }}{30}{figure.caption.8}\protected@file@percent }
\newlabel{fig:18ott1}{{6.1}{30}{Geometric idea.\relax }{figure.caption.8}{}}
\newlabel{fig:18ott1@cref}{{[figure][1][6]6.1}{[1][30][]30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}QR factorization}{31}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces On the left in $\mathds  {R}^{2}$, on the right in $\mathds  {R}^{3}$.\relax }}{32}{figure.caption.9}\protected@file@percent }
\newlabel{fig:18ott2}{{6.2}{32}{On the left in $\mathds {R}^{2}$, on the right in $\mathds {R}^{3}$.\relax }{figure.caption.9}{}}
\newlabel{fig:18ott2@cref}{{[figure][2][6]6.2}{[1][32][]32}}
\@writefile{toc}{\contentsline {section}{\numberline {7}26th of October 2018 --- F. Poloni}{34}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}How to construct a QR factorization}{34}{subsection.7.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {7.1}{\ignorespaces Householder vector Matlab implementation.\relax }}{34}{algorithm.7.1}\protected@file@percent }
\newlabel{alg:26ott1}{{7.1}{34}{Householder vector Matlab implementation.\relax }{algorithm.7.1}{}}
\newlabel{alg:26ott1@cref}{{[algorithm][1][7]7.1}{[1][34][]34}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces If $x$ is oriented as in the plot it's better if we choose $-\Vert x\Vert  e_{1}$ verse, since it's opposite to $x$.\relax }}{34}{figure.caption.10}\protected@file@percent }
\newlabel{fig:26ott1}{{7.1}{34}{If $x$ is oriented as in the plot it's better if we choose $-\|x\| e_{1}$ verse, since it's opposite to $x$.\relax }{figure.caption.10}{}}
\newlabel{fig:26ott1@cref}{{[figure][1][7]7.1}{[1][34][]34}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1}Matlab implementation}{36}{subsubsection.7.1.1}\protected@file@percent }
\newlabel{alg:26ottQR1}{{\caption@xref {alg:26ottQR1}{ on input line 211}}{36}{Matlab implementation}{subsubsection.7.1.1}{}}
\newlabel{alg:26ottQR1@cref}{{[subsubsection][1][7,1]7.1.1}{[1][36][]36}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7.2}{\ignorespaces First implementation of QR factorization.\relax }}{36}{algorithm.7.2}\protected@file@percent }
\newlabel{alg:26ottQR2}{{\caption@xref {alg:26ottQR2}{ on input line 242}}{37}{Matlab implementation}{theorem.7.2}{}}
\newlabel{alg:26ottQR2@cref}{{[subsubsection][1][7,1]7.1.1}{[1][37][]37}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {7.3}{\ignorespaces More efficient implementation of QR factorization.\relax }}{37}{algorithm.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}How to use the thin QR factorization to solve a least squares problem}{38}{subsection.7.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}7th of November 2018 --- F.Poloni}{40}{section.8}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Least squares problem with SVD}{40}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1}Behaviour in case of zeros as singular values}{43}{subsubsection.8.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}Truncated SVD}{44}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Tikhonov regularization / ridge regression}{44}{subsection.8.3}\protected@file@percent }
\newlabel{eq:7novxtik}{{8.3}{44}{}{equation.8.3}{}}
\newlabel{eq:7novxtik@cref}{{[equation][3][8]8.3}{[1][44][]44}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Here is the shape of the formula for the singular values.\relax }}{46}{figure.caption.12}\protected@file@percent }
\newlabel{fig:7nov1}{{8.1}{46}{Here is the shape of the formula for the singular values.\relax }{figure.caption.12}{}}
\newlabel{fig:7nov1@cref}{{[figure][1][8]8.1}{[1][45][]46}}
\@writefile{toc}{\contentsline {section}{\numberline {9}9th of November 2018 --- F. Poloni}{46}{section.9}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Conditioning}{46}{subsection.9.1}\protected@file@percent }
\newlabel{ex:9nov1}{{9.1}{46}{}{example.9.1}{}}
\newlabel{ex:9nov1@cref}{{[example][1][9]9.1}{[1][46][]46}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Geometric idea of temperature of the water in the shower\relax }}{47}{figure.caption.13}\protected@file@percent }
\newlabel{fig:9nov1}{{9.1}{47}{Geometric idea of temperature of the water in the shower\relax }{figure.caption.13}{}}
\newlabel{fig:9nov1@cref}{{[figure][1][9]9.1}{[1][46][]47}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Geometric idea behind the derivative, as ``zoom'' of the function in a certain point.\relax }}{47}{figure.caption.14}\protected@file@percent }
\newlabel{fig:9nov2}{{9.2}{47}{Geometric idea behind the derivative, as ``zoom'' of the function in a certain point.\relax }{figure.caption.14}{}}
\newlabel{fig:9nov2@cref}{{[figure][2][9]9.2}{[1][47][]47}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Geometric idea behind absolute condition number.\relax }}{48}{figure.caption.15}\protected@file@percent }
\newlabel{fig:9nov3}{{9.3}{48}{Geometric idea behind absolute condition number.\relax }{figure.caption.15}{}}
\newlabel{fig:9nov3@cref}{{[figure][3][9]9.3}{[1][47][]48}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces Paraboloid\relax }}{48}{figure.caption.16}\protected@file@percent }
\newlabel{fig:9nov4}{{9.4}{48}{Paraboloid\relax }{figure.caption.16}{}}
\newlabel{fig:9nov4@cref}{{[figure][4][9]9.4}{[1][48][]48}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces Level curves of a quadratic function (``seen from above'').\relax }}{49}{figure.caption.17}\protected@file@percent }
\newlabel{fig:9nov4}{{9.5}{49}{Level curves of a quadratic function (``seen from above'').\relax }{figure.caption.17}{}}
\newlabel{fig:9nov4@cref}{{[figure][5][9]9.5}{[1][49][]49}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.1}Conditioning of linear systems}{50}{subsubsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Condition number, SVD, and distance to singularity}{51}{subsection.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Conditioning of least squares problem}{52}{subsection.9.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces The triangle in the figure (the one whose cathets are $Ax$ and $b-Ax$) is a square triangle.\relax }}{53}{figure.caption.18}\protected@file@percent }
\newlabel{fig:9nov6}{{9.6}{53}{The triangle in the figure (the one whose cathets are $Ax$ and $b-Ax$) is a square triangle.\relax }{figure.caption.18}{}}
\newlabel{fig:9nov6@cref}{{[figure][6][9]9.6}{[1][52][]53}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Special case 1\relax }}{53}{figure.caption.19}\protected@file@percent }
\newlabel{fig:9nov7}{{9.7}{53}{Special case 1\relax }{figure.caption.19}{}}
\newlabel{fig:9nov7@cref}{{[figure][7][9]9.7}{[1][53][]53}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces Special case 2.\relax }}{54}{figure.caption.20}\protected@file@percent }
\newlabel{fig:9nov8}{{9.8}{54}{Special case 2.\relax }{figure.caption.20}{}}
\newlabel{fig:9nov8@cref}{{[figure][8][9]9.8}{[1][53][]54}}
\@writefile{toc}{\contentsline {section}{\numberline {10}15th of November 2018 --- F. Poloni}{55}{section.10}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Stability of algorithms}{55}{subsection.10.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.1}{\ignorespaces We have $2^{52}$ equispaced numbers between $\genfrac  {}{}{}{}{1}{2}$ and $1$ and between $1$ and $2$, and also $2^{52}$ between $2$ and $4$ and so on and so forth, so we have the same number of integers, although the space is enlarging.\relax }}{55}{figure.caption.21}\protected@file@percent }
\newlabel{fig:15nov1}{{10.1}{55}{We have $2^{52}$ equispaced numbers between $\frac {1}{2}$ and $1$ and between $1$ and $2$, and also $2^{52}$ between $2$ and $4$ and so on and so forth, so we have the same number of integers, although the space is enlarging.\relax }{figure.caption.21}{}}
\newlabel{fig:15nov1@cref}{{[figure][1][10]10.1}{[1][55][]55}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Backward stability of QR factorization}{59}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}Stability of algorithms for least-squares problems}{60}{subsubsection.10.2.1}\protected@file@percent }
\@writefile{tdo}{\contentsline {todo}{Scrivere meglio}{60}{section*.22}\protected@file@percent }
\pgfsyspdfmark {pgfid49}{4736286}{18209814}
\pgfsyspdfmark {pgfid52}{38025806}{18226738}
\pgfsyspdfmark {pgfid53}{39874101}{17955862}
\@writefile{lof}{\contentsline {figure}{\numberline {10.2}{\ignorespaces $b$ lies (at least almost, because of numerical error) on the plane of $Im(A)$. In this case $\kappa _{rel}(\text  {solving LS}) \approx \kappa (A)$.\relax }}{61}{figure.caption.23}\protected@file@percent }
\newlabel{fig:15nov2}{{10.2}{61}{$b$ lies (at least almost, because of numerical error) on the plane of $Im(A)$. In this case $\kappa _{rel}(\text {solving LS}) \approx \kappa (A)$.\relax }{figure.caption.23}{}}
\newlabel{fig:15nov2@cref}{{[figure][2][10]10.2}{[1][61][]61}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}A posteriori checks}{61}{subsubsection.10.2.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Brief recap of the complexities of the algorithms we studied for solving the least squares problem. The last row takes into account the stability.\relax }}{62}{table.caption.24}\protected@file@percent }
\newlabel{tab:15nov1}{{1}{62}{Brief recap of the complexities of the algorithms we studied for solving the least squares problem. The last row takes into account the stability.\relax }{table.caption.24}{}}
\newlabel{tab:15nov1@cref}{{[table][1][]1}{[1][61][]62}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}A posteriori check for Least Squares Problems}{63}{subsection.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {10.3}{\ignorespaces $A$ can be as large as $b$ if $b$ is perfectly orthogonal.\relax }}{63}{figure.caption.25}\protected@file@percent }
\newlabel{fig:15nov3}{{10.3}{63}{$A$ can be as large as $b$ if $b$ is perfectly orthogonal.\relax }{figure.caption.25}{}}
\newlabel{fig:15nov3@cref}{{[figure][3][10]10.3}{[1][63][]63}}
\@writefile{toc}{\contentsline {section}{\numberline {11}21st of November 2018 --- F. Poloni}{65}{section.11}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11.1}{\ignorespaces A local function on graph.\relax }}{65}{figure.caption.26}\protected@file@percent }
\newlabel{fig:21nov1}{{11.1}{65}{A local function on graph.\relax }{figure.caption.26}{}}
\newlabel{fig:21nov1@cref}{{[figure][1][11]11.1}{[1][65][]65}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.2}{\ignorespaces Graphic idea of a bridge partitioned into small blocks\relax }}{66}{figure.caption.27}\protected@file@percent }
\newlabel{fig:21nov2}{{11.2}{66}{Graphic idea of a bridge partitioned into small blocks\relax }{figure.caption.27}{}}
\newlabel{fig:21nov2@cref}{{[figure][2][11]11.2}{[1][65][]66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Gaussian elimination and LU factorization}{66}{subsection.11.1}\protected@file@percent }
\newlabel{obs:21novstroke1}{{11.1}{67}{Stroke of luck}{obs.11.1}{}}
\newlabel{obs:21novstroke1@cref}{{[obs][1][11]11.1}{[1][67][]67}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {11.1}{\ignorespaces LU factorization, Matlab implementation.\relax }}{68}{algorithm.11.1}\protected@file@percent }
\newlabel{algo:21nov1}{{11.1}{68}{LU factorization, Matlab implementation.\relax }{algorithm.11.1}{}}
\newlabel{algo:21nov1@cref}{{[algorithm][1][11]11.1}{[1][67][]68}}
\@writefile{lof}{\contentsline {figure}{\numberline {11.3}{\ignorespaces Assuming that we are at step $k$, we have that the $h$-th multiplier is expressed as $\genfrac  {}{}{}{}{A_{hk}}{A_{kk}}$ and this muliplier goes to the right position in $L$.\relax }}{68}{figure.caption.28}\protected@file@percent }
\newlabel{fig:21nov3}{{11.3}{68}{Assuming that we are at step $k$, we have that the $h$-th multiplier is expressed as $\frac {A_{hk}}{A_{kk}}$ and this muliplier goes to the right position in $L$.\relax }{figure.caption.28}{}}
\newlabel{fig:21nov3@cref}{{[figure][3][11]11.3}{[1][68][]68}}
\@writefile{tdo}{\contentsline {todo}{missing}{69}{section*.29}\protected@file@percent }
\pgfsyspdfmark {pgfid64}{4736286}{27604232}
\pgfsyspdfmark {pgfid67}{38025806}{27621156}
\pgfsyspdfmark {pgfid68}{39874101}{27350280}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.1}Stability of LU}{69}{subsubsection.11.1.1}\protected@file@percent }
\newlabel{21novstability}{{11.1.1}{69}{Stability of LU}{subsubsection.11.1.1}{}}
\newlabel{21novstability@cref}{{[subsubsection][1][11,1]11.1.1}{[1][69][]69}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {11.1.2}Gaussian elimination on sparse matrices}{70}{subsubsection.11.1.2}\protected@file@percent }
\@writefile{toc}{\tof@stoptags{myfile1}}
\@writefile{toc}{\contentsline {section}{\numberline {12}23rd of November 2018 --- F. Poloni}{72}{section.12}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.1}Gaussian elimination on symmetric matrices}{72}{subsection.12.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {12.1}{\ignorespaces Symmetric Gaussian factorization, Matlab implementation.\relax }}{73}{algorithm.12.1}\protected@file@percent }
\newlabel{algo:23novsymgauss}{{12.1}{73}{Symmetric Gaussian factorization, Matlab implementation.\relax }{algorithm.12.1}{}}
\newlabel{algo:23novsymgauss@cref}{{[algorithm][1][12]12.1}{[1][73][]73}}
\newlabel{lemma:23nov1}{{12.2}{73}{}{theorem.12.2}{}}
\newlabel{lemma:23nov1@cref}{{[lemma][2][12]12.2}{[1][73][]73}}
\@writefile{toc}{\contentsline {subsection}{\numberline {12.2}Cholesky factorization}{75}{subsection.12.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {12.3}Krylov subspace methods}{75}{subsection.12.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {13}29th of November 2018 --- F. Poloni}{78}{section.13}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {13.0.1}Naive idea}{78}{subsubsection.13.0.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {13.0.2}Improvement}{78}{subsubsection.13.0.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1}Arnoldi algorithm}{78}{subsection.13.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {13.1}{\ignorespaces Arnoldi algorithm Matlab implementation.\relax }}{79}{algorithm.13.1}\protected@file@percent }
\newlabel{alg:29novarnoldi}{{13.1}{79}{Arnoldi algorithm Matlab implementation.\relax }{algorithm.13.1}{}}
\newlabel{alg:29novarnoldi@cref}{{[algorithm][1][13]13.1}{[1][79][]79}}
\@writefile{lof}{\contentsline {figure}{\numberline {13.1}{\ignorespaces We started form a matirx $A$ which has many entries and it gets factorized by the product of two smaller matrices\relax }}{80}{figure.caption.30}\protected@file@percent }
\newlabel{fig:29nov1}{{13.1}{80}{We started form a matirx $A$ which has many entries and it gets factorized by the product of two smaller matrices\relax }{figure.caption.30}{}}
\newlabel{fig:29nov1@cref}{{[figure][1][13]13.1}{[1][80][]80}}
\@writefile{toc}{\contentsline {section}{\numberline {14}5th of December 2018 --- F. Poloni}{83}{section.14}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {14.1}Convergence of Arnoldi}{83}{subsection.14.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {14.1.1}Better explanation}{84}{subsubsection.14.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {15}7th of December 2018 --- F. Poloni}{86}{section.15}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15.1}{\ignorespaces In this picture the eigenvalues are clustered around $P_1, P_2, P_3$ and $P_4$. We can find a polynomial $q$ such that $q(\text  {red points}) \approx 0$.\relax }}{88}{figure.caption.31}\protected@file@percent }
\newlabel{fig:7diceigen}{{15.1}{88}{In this picture the eigenvalues are clustered around $P_1, P_2, P_3$ and $P_4$. We can find a polynomial $q$ such that $q(\text {red points}) \approx 0$.\relax }{figure.caption.31}{}}
\newlabel{fig:7diceigen@cref}{{[figure][1][15]15.1}{[1][87][]88}}
\@writefile{toc}{\contentsline {section}{\numberline {16}13th of December 2018 --- F. Poloni}{89}{section.16}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {16.1}Lanczos algorithm}{89}{subsection.16.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {16.1}{\ignorespaces Pseudocode for the conjugate gradient method.\relax }}{89}{algorithm.16.1}\protected@file@percent }
\newlabel{alg:7dic_ConjGrad}{{16.1}{89}{Pseudocode for the conjugate gradient method.\relax }{algorithm.16.1}{}}
\newlabel{alg:7dic_ConjGrad@cref}{{[algorithm][1][16]16.1}{[1][89][]89}}
\newlabel{subfloat:13dic_arnoldi}{{16.1(a)}{90}{Subfigure 16.1(a)}{subfigure.16.1.1}{}}
\newlabel{subfloat:13dic_arnoldi@cref}{{[subfigure][1][16,1]16.1(a)}{[1][90][]90}}
\newlabel{sub@subfloat:13dic_arnoldi}{{(a)}{90}{Subfigure 16.1(a)\relax }{subfigure.16.1.1}{}}
\newlabel{subfloat:13dic_cg}{{16.1(b)}{90}{Subfigure 16.1(b)}{subfigure.16.1.2}{}}
\newlabel{subfloat:13dic_cg@cref}{{[subfigure][2][16,1]16.1(b)}{[1][90][]90}}
\newlabel{sub@subfloat:13dic_cg}{{(b)}{90}{Subfigure 16.1(b)\relax }{subfigure.16.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16.1}{\ignorespaces Traditional orthogonality (Arnoldi) leads to the minimization of the 2-norm, while in the conjugate gradient we impose A-orthogonality and we get a good approximation in several norms.\relax }}{90}{figure.caption.32}\protected@file@percent }
\newlabel{fig:13dic_parallel}{{16.1}{90}{Traditional orthogonality (Arnoldi) leads to the minimization of the 2-norm, while in the conjugate gradient we impose A-orthogonality and we get a good approximation in several norms.\relax }{figure.caption.32}{}}
\newlabel{fig:13dic_parallel@cref}{{[figure][1][16]16.1}{[1][90][]90}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Arnoldi}}}{90}{figure.caption.32}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Conjugate gradient}}}{90}{figure.caption.32}\protected@file@percent }
\gdef\minted@oldcachelist{,
  default-pyg-prefix.pygstyle,
  default.pygstyle,
  EED6737C5336486CEEE35048F0DD4656EA874F595B2B8948FD4AD3908D478650.pygtex,
  E712477AB9939FB1E350DC42BBF9460AEA874F595B2B8948FD4AD3908D478650.pygtex,
  22342908BBF7FA85E77936BCA1943F3FEA874F595B2B8948FD4AD3908D478650.pygtex,
  506BE4FD22EE5A450C6DCC263C742067EA874F595B2B8948FD4AD3908D478650.pygtex,
  59DABF05D239FC17059D5272C76C11DDEA874F595B2B8948FD4AD3908D478650.pygtex,
  BD99D526AD70755A2045B543225F4CD5EA874F595B2B8948FD4AD3908D478650.pygtex,
  49F3809EE2A24D3923D3316C5317033FEA874F595B2B8948FD4AD3908D478650.pygtex,
  F7F54B3589E7236ADB558887A5B22C2FEA874F595B2B8948FD4AD3908D478650.pygtex}
\@writefile{toc}{\tof@finish}
